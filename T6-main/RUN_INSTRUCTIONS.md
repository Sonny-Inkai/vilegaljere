# ğŸš€ HÆ¯á»šNG DáºªN CHáº Y ViLegalJERE

## ğŸ”§ CÃ¡c váº¥n Ä‘á» Ä‘Ã£ Ä‘Æ°á»£c sá»­a:

### âŒ **Váº¥n Ä‘á» trÆ°á»›c Ä‘Ã¢y:**
1. **Tokenizer thiáº¿u special tokens** â†’ Model khÃ´ng hiá»ƒu `<ORGANIZATION>`, `<LEGAL_PROVISION>`, etc.
2. **Vocab size mismatch** â†’ Model vÃ  tokenizer khÃ´ng khá»›p
3. **Sai format parsing** â†’ Extraction function khÃ´ng parse Ä‘Ãºng format

### âœ… **CÃ¡c fix Ä‘Ã£ Ã¡p dá»¥ng:**
1. **ThÃªm Ä‘Ãºng special tokens vÃ o tokenizer**
2. **Resize model embeddings Ä‘á»ƒ match tokenizer**
3. **Parse Ä‘Ãºng format: `<HEAD_TYPE> head_text <TAIL_TYPE> tail_text <RELATION>`**
4. **Optimize generation parameters**

---

## ğŸ“‹ TRÃŒNH Tá»° CHáº Y:

### **BÆ°á»›c 1: Test Tokenizer**
```bash
cd T6-main
python test_tokenizer.py
```
**Ká»³ vá»ng:** Táº¥t cáº£ special tokens hiá»ƒn thá»‹ âœ… OK

### **BÆ°á»›c 2: Test Minimal Training Setup**
```bash
python test_training.py
```
**Ká»³ vá»ng:** ALL TESTS PASSED!

### **BÆ°á»›c 3: Cháº¡y Training**
```bash
# Pre-training (náº¿u muá»‘n)
python train_vilegal_jere.py

# Hoáº·c chá»‰ Fine-tuning
# Äáº£m báº£o finetune = True trong script
python train_vilegal_jere.py
```

### **BÆ°á»›c 4: Test Generation**
```bash
python generate.py
```

---

## ğŸ¯ Format dá»¯ liá»‡u cá»§a chÃ¡u:

**Input (Context):**
```
Äiá»u 51: Tham gia cá»§a nhÃ  Ä‘áº§u tÆ° nÆ°á»›c ngoÃ i trÃªn thá»‹ trÆ°á»ng chá»©ng khoÃ¡n Viá»‡t Nam...
```

**Output (Relations):**
```
<ORGANIZATION> nhÃ  Ä‘áº§u tÆ° nÆ°á»›c ngoÃ i <LOCATION> thá»‹ trÆ°á»ng chá»©ng khoÃ¡n Viá»‡t Nam <Relates_To> <LEGAL_PROVISION> phÃ¡p luáº­t vá» chá»©ng khoÃ¡n <LOCATION> thá»‹ trÆ°á»ng chá»©ng khoÃ¡n Viá»‡t Nam <Relates_To>
```

**Cáº¥u trÃºc:** `<HEAD_TYPE> head_text <TAIL_TYPE> tail_text <RELATION_TYPE>`

---

## ğŸš¨ Troubleshooting:

### Náº¿u váº«n generate vÃ´ nghÄ©a:
1. **Check tokenizer:** Run `test_tokenizer.py` xem special tokens cÃ³ âœ… khÃ´ng
2. **Check model vocab:** Äáº£m báº£o `model.config.vocab_size == len(tokenizer)`
3. **Check data format:** Xem sample trong training log cÃ³ Ä‘Ãºng format khÃ´ng

### Náº¿u training bá»‹ lá»—i:
1. **Memory error:** Giáº£m `batch_size` tá»« 32 â†’ 16
2. **CUDA error:** Set `device = 'cpu'` Ä‘á»ƒ test
3. **Data loading error:** Check `data_path` vÃ  file `finetune.json`

---

## ğŸ“Š Expected Results:

**TrÆ°á»›c khi sá»­a:**
```
ğŸ¤– MODEL GENERATED:
,,, nghiá»‡p há»£p doanh cÆ¡ thÃ´ng Ä‘áº¥t tá»« bÃ¹ há»£p há»™ TÃ²a cÃ³ Ä‘Æ°á»£c quy trong theo quy
```

**Sau khi sá»­a (ká»³ vá»ng):**
```
ğŸ¤– MODEL GENERATED:
<ORGANIZATION> nhÃ  Ä‘áº§u tÆ° nÆ°á»›c ngoÃ i <LOCATION> thá»‹ trÆ°á»ng chá»©ng khoÃ¡n Viá»‡t Nam <Relates_To>
ğŸ¯ Extracted 1 relations:
   1. nhÃ  Ä‘áº§u tÆ° nÆ°á»›c ngoÃ i (ORGANIZATION) --Relates_To--> thá»‹ trÆ°á»ng chá»©ng khoÃ¡n Viá»‡t Nam (LOCATION)
```

---

## ğŸ¯ Key Changes Made:

1. **train_vilegal_jere.py:**
   - âœ… Added domain special tokens to tokenizer
   - âœ… Removed unnecessary triplet tokens
   - âœ… Fixed data loading format

2. **generate.py:**
   - âœ… Fixed tokenizer setup
   - âœ… Improved relation extraction parsing
   - âœ… Better generation parameters

3. **model/ViLegalJERE.py:**
   - âœ… Proper token embedding resizing
   - âœ… Correct attention mask handling

**Cháº¡y ngay Ä‘á»ƒ test nhÃ© chÃ¡u! ğŸš€** 