import torch
import json
from transformers import AutoTokenizer
from model.ViLegalJERE import ViLegalJERE

def load_model_and_tokenizer(model_path="/kaggle/working/out_vilegal_t5small"):
    """Load finetuned model and tokenizer"""
    try:
        model = ViLegalJERE.from_pretrained(model_path)
        tokenizer = AutoTokenizer.from_pretrained('sonny36/vilegaljere')
        
        # ‚úÖ FIX: Th√™m t·∫•t c·∫£ special tokens c·∫ßn thi·∫øt cho Vietnamese Legal JERE
        domain_special_tokens = [
            "<ORGANIZATION>", "<LOCATION>", "<DATE/TIME>", "<LEGAL_PROVISION>",
            "<RIGHT/DUTY>", "<PERSON>", "<Effective_From>", "<Applicable_In>",
            "<Relates_To>", "<Amended_By>"
        ]
        
        # ‚úÖ FIX: Kh√¥ng c·∫ßn triplet tokens v√¨ ch√°u d√πng format ri√™ng
        # triplet_tokens = ["<triplet>", "<subj>", "<obj>"]  # B·ªè d√≤ng n√†y
        
        # ‚úÖ FIX: Ch·ªâ d√πng domain special tokens  
        all_special_tokens = domain_special_tokens
        
        # ‚úÖ FIX: Th√™m v√†o tokenizer
        tokenizer.add_tokens(all_special_tokens, special_tokens=True)
        
        print(f"‚úÖ Added {len(all_special_tokens)} special tokens to tokenizer")
        print(f"New tokenizer vocab size: {len(tokenizer)}")
        
        # ‚úÖ FIX: Model ph·∫£i resize ƒë·ªÉ match tokenizer
        if model.config.vocab_size != len(tokenizer):
            print(f"üîß Resizing model embeddings from {model.config.vocab_size} to {len(tokenizer)}")
            model.resize_token_embeddings(len(tokenizer))
        
        model.eval()
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model.to(device)
        print(f"Model loaded successfully on {device}")
        print(f"Model vocab size: {model.config.vocab_size}")
        print(f"Tokenizer vocab size: {len(tokenizer)}")
        return model, tokenizer, device
    except Exception as e:
        print(f"Error loading model: {e}")
        return None, None, None

def extract_vietnamese_legal_relations(text):
    """
    Tr√≠ch xu·∫•t relations t·ª´ generated text theo format Vietnamese Legal JERE
    Format: <ENTITY_TYPE> entity_text <ENTITY_TYPE> entity_text <RELATION_TYPE>
    """
    relations = []
    
    # L√†m s·∫°ch text
    text = text.replace("<s>", "").replace("</s>", "").replace("<pad>", "").strip()
    
    # ‚úÖ FIX: Parse theo format c·ªßa ch√°u: <HEAD_TYPE> head_text <TAIL_TYPE> tail_text <RELATION>
    tokens = text.split()
    
    # Entity v√† relation types
    entity_types = ["<ORGANIZATION>", "<LOCATION>", "<LEGAL_PROVISION>", "<RIGHT/DUTY>", "<PERSON>", "<DATE/TIME>"]
    relation_types = ["<Relates_To>", "<Effective_From>", "<Applicable_In>", "<Amended_By>"]
    
    i = 0
    while i < len(tokens):
        # T√¨m head entity
        if tokens[i] in entity_types:
            head_type = tokens[i]
            head_text = ""
            i += 1
            
            # Collect head text until next entity type
            while i < len(tokens) and tokens[i] not in entity_types and tokens[i] not in relation_types:
                head_text += " " + tokens[i]
                i += 1
            
            # T√¨m tail entity
            if i < len(tokens) and tokens[i] in entity_types:
                tail_type = tokens[i]
                tail_text = ""
                i += 1
                
                # Collect tail text until relation type
                while i < len(tokens) and tokens[i] not in entity_types and tokens[i] not in relation_types:
                    tail_text += " " + tokens[i]
                    i += 1
                
                # T√¨m relation
                if i < len(tokens) and tokens[i] in relation_types:
                    relation = tokens[i]
                    
                    # T·∫°o triplet
                    if head_text.strip() and tail_text.strip():
                        relations.append({
                            'head': head_text.strip(),
                            'head_type': head_type.replace('<', '').replace('>', ''),
                            'tail': tail_text.strip(),
                            'tail_type': tail_type.replace('<', '').replace('>', ''),
                            'relation': relation.replace('<', '').replace('>', '')
                        })
                    i += 1
                else:
                    i += 1
            else:
                i += 1
        else:
            i += 1
    
    return relations

def generate_relations(model, tokenizer, device, context_text, max_length=512):
    """Generate relation extraction from context"""
    # Tokenize input (encoder input)
    inputs = tokenizer(
        context_text,
        max_length=max_length,
        truncation=True,
        padding=True,
        return_tensors="pt"
    ).to(device)
    
    # ‚úÖ FIX: S·ª≠ d·ª•ng generation parameters t·ªët h∆°n
    with torch.no_grad():
        outputs = model.generate(
            input_ids=inputs['input_ids'],
            attention_mask=inputs['attention_mask'],
            max_length=max_length,
            do_sample=False,  # ‚úÖ S·ª≠ d·ª•ng deterministic generation ƒë·ªÉ debug
            num_beams=3,      # ‚úÖ Beam search cho output ·ªïn ƒë·ªãnh h∆°n
            early_stopping=True,
            pad_token_id=tokenizer.pad_token_id,
            eos_token_id=tokenizer.eos_token_id,
            no_repeat_ngram_size=2  # ‚úÖ Tr√°nh l·∫∑p l·∫°i
        )
    
    # Decode output (skip the start token)
    generated_text = tokenizer.decode(outputs[0, 1:], skip_special_tokens=False)
    
    # ‚úÖ Tr√≠ch xu·∫•t relations theo format Vietnamese Legal
    relations = extract_vietnamese_legal_relations(generated_text)
    
    return generated_text, relations

def test_model():
    """Test model with 3 sample cases"""
    model, tokenizer, device = load_model_and_tokenizer()
    
    if model is None:
        print("Failed to load model. Exiting...")
        return
    
    # Test cases from your data
    test_cases = [
        {
            "id": "54/2019/QH14__Dieu51",
            "context": "ƒêi·ªÅu 51: Tham gia c·ªßa nh√† ƒë·∫ßu t∆∞ n∆∞·ªõc ngo√†i, t·ªï ch·ª©c kinh t·∫ø c√≥ v·ªën ƒë·∫ßu t∆∞ n∆∞·ªõc ngo√†i tr√™n th·ªã tr∆∞·ªùng ch·ª©ng kho√°n Vi·ªát Nam 1. Nh√† ƒë·∫ßu t∆∞ n∆∞·ªõc ngo√†i, t·ªï ch·ª©c kinh t·∫ø c√≥ v·ªën ƒë·∫ßu t∆∞ n∆∞·ªõc ngo√†i khi tham gia ƒë·∫ßu t∆∞, ho·∫°t ƒë·ªông tr√™n th·ªã tr∆∞·ªùng ch·ª©ng kho√°n Vi·ªát Nam tu√¢n th·ªß quy ƒë·ªãnh v·ªÅ t·ª∑ l·ªá s·ªü h·ªØu n∆∞·ªõc ngo√†i, ƒëi·ªÅu ki·ªán, tr√¨nh t·ª±, th·ªß t·ª•c ƒë·∫ßu t∆∞ theo quy ƒë·ªãnh c·ªßa ph√°p lu·∫≠t v·ªÅ ch·ª©ng kho√°n v√† th·ªã tr∆∞·ªùng ch·ª©ng kho√°n. 2. Ch√≠nh ph·ªß quy ƒë·ªãnh chi ti·∫øt t·ª∑ l·ªá s·ªü h·ªØu n∆∞·ªõc ngo√†i, ƒëi·ªÅu ki·ªán, tr√¨nh t·ª±, th·ªß t·ª•c ƒë·∫ßu t∆∞, vi·ªác tham gia c·ªßa nh√† ƒë·∫ßu t∆∞ n∆∞·ªõc ngo√†i, t·ªï ch·ª©c kinh t·∫ø c√≥ v·ªën ƒë·∫ßu t∆∞ n∆∞·ªõc ngo√†i tr√™n th·ªã tr∆∞·ªùng ch·ª©ng kho√°n Vi·ªát Nam.",
            "expected": "<ORGANIZATION> t·ªï ch·ª©c kinh t·∫ø c√≥ v·ªën ƒë·∫ßu t∆∞ n∆∞·ªõc ngo√†i <LOCATION> th·ªã tr∆∞·ªùng ch·ª©ng kho√°n Vi·ªát Nam <Relates_To> <LEGAL_PROVISION> ph√°p lu·∫≠t v·ªÅ ch·ª©ng kho√°n v√† th·ªã tr∆∞·ªùng ch·ª©ng kho√°n <LOCATION> th·ªã tr∆∞·ªùng ch·ª©ng kho√°n Vi·ªát Nam <Relates_To> <ORGANIZATION> Ch√≠nh ph·ªß <ORGANIZATION> t·ªï ch·ª©c kinh t·∫ø c√≥ v·ªën ƒë·∫ßu t∆∞ n∆∞·ªõc ngo√†i <Relates_To> <ORGANIZATION> t·ªï ch·ª©c kinh t·∫ø c√≥ v·ªën ƒë·∫ßu t∆∞ n∆∞·ªõc ngo√†i <LOCATION> th·ªã tr∆∞·ªùng ch·ª©ng kho√°n Vi·ªát Nam <Relates_To>"
        },
        {
            "id": "59/2020/QH14__Dieu173", 
            "context": "ƒêi·ªÅu 173: Tr√°ch nhi·ªám c·ªßa Ki·ªÉm so√°t vi√™n 1. Tu√¢n th·ªß ƒë√∫ng ph√°p lu·∫≠t, ƒêi·ªÅu l·ªá c√¥ng ty, ngh·ªã quy·∫øt ƒê·∫°i h·ªôi ƒë·ªìng c·ªï ƒë√¥ng v√† ƒë·∫°o ƒë·ª©c ngh·ªÅ nghi·ªáp trong th·ª±c hi·ªán quy·ªÅn v√† nghƒ©a v·ª• ƒë∆∞·ª£c giao. 2. Th·ª±c hi·ªán quy·ªÅn v√† nghƒ©a v·ª• ƒë∆∞·ª£c giao m·ªôt c√°ch trung th·ª±c, c·∫©n tr·ªçng, t·ªët nh·∫•t nh·∫±m b·∫£o ƒë·∫£m l·ª£i √≠ch h·ª£p ph√°p t·ªëi ƒëa c·ªßa c√¥ng ty. 3. Trung th√†nh v·ªõi l·ª£i √≠ch c·ªßa c√¥ng ty v√† c·ªï ƒë√¥ng; kh√¥ng l·∫°m d·ª•ng ƒë·ªãa v·ªã, ch·ª©c v·ª• v√† s·ª≠ d·ª•ng th√¥ng tin, b√≠ quy·∫øt, c∆° h·ªôi kinh doanh, t√†i s·∫£n kh√°c c·ªßa c√¥ng ty ƒë·ªÉ t∆∞ l·ª£i ho·∫∑c ph·ª•c v·ª• l·ª£i √≠ch c·ªßa t·ªï ch·ª©c, c√° nh√¢n kh√°c. 4. Nghƒ©a v·ª• kh√°c theo quy ƒë·ªãnh c·ªßa Lu·∫≠t n√†y v√† ƒêi·ªÅu l·ªá c√¥ng ty. 5. Tr∆∞·ªùng h·ª£p vi ph·∫°m quy ƒë·ªãnh t·∫°i c√°c kho·∫£n 1, 2, 3 v√† 4 ƒêi·ªÅu n√†y m√† g√¢y thi·ªát h·∫°i cho c√¥ng ty ho·∫∑c ng∆∞·ªùi kh√°c th√¨ Ki·ªÉm so√°t vi√™n ph·∫£i ch·ªãu tr√°ch nhi·ªám c√° nh√¢n ho·∫∑c li√™n ƒë·ªõi b·ªìi th∆∞·ªùng thi·ªát h·∫°i ƒë√≥. Thu nh·∫≠p v√† l·ª£i √≠ch kh√°c m√† Ki·ªÉm so√°t vi√™n c√≥ ƒë∆∞·ª£c do vi ph·∫°m ph·∫£i ho√†n tr·∫£ cho c√¥ng ty. 6. Tr∆∞·ªùng h·ª£p ph√°t hi·ªán c√≥ Ki·ªÉm so√°t vi√™n vi ph·∫°m trong th·ª±c hi·ªán quy·ªÅn v√† nghƒ©a v·ª• ƒë∆∞·ª£c giao th√¨ ph·∫£i th√¥ng b√°o b·∫±ng vƒÉn b·∫£n ƒë·∫øn Ban ki·ªÉm so√°t; y√™u c·∫ßu ng∆∞·ªùi c√≥ h√†nh vi vi ph·∫°m ch·∫•m d·ª©t h√†nh vi vi ph·∫°m v√† kh·∫Øc ph·ª•c h·∫≠u qu·∫£.",
            "expected": "<RIGHT/DUTY> Tu√¢n th·ªß ƒë√∫ng ph√°p lu·∫≠t, ƒêi·ªÅu l·ªá c√¥ng ty, ngh·ªã quy·∫øt ƒê·∫°i h·ªôi ƒë·ªìng c·ªï ƒë√¥ng v√† ƒë·∫°o ƒë·ª©c ngh·ªÅ nghi·ªáp trong th·ª±c hi·ªán quy·ªÅn v√† nghƒ©a v·ª• ƒë∆∞·ª£c giao <LEGAL_PROVISION> ƒêi·ªÅu 173 <Relates_To> <RIGHT/DUTY> Th·ª±c hi·ªán quy·ªÅn v√† nghƒ©a v·ª• ƒë∆∞·ª£c giao m·ªôt c√°ch trung th·ª±c, c·∫©n tr·ªçng, t·ªët nh·∫•t nh·∫±m b·∫£o ƒë·∫£m l·ª£i √≠ch h·ª£p ph√°p t·ªëi ƒëa c·ªßa c√¥ng ty <LEGAL_PROVISION> ƒêi·ªÅu 173 <Relates_To>"
        },
        {
            "id": "54/2019/QH14__Dieu63",
            "context": "ƒêi·ªÅu 63: B·ª´ tr·ª´ v√† thanh to√°n giao d·ªãch ch·ª©ng kho√°n 1. Ho·∫°t ƒë·ªông b√π tr·ª´, x√°c ƒë·ªãnh nghƒ©a v·ª• thanh to√°n ti·ªÅn v√† ch·ª©ng kho√°n ƒë∆∞·ª£c th·ª±c hi·ªán th√¥ng qua T·ªïng c√¥ng ty l∆∞u k√Ω v√† b√π tr·ª´ ch·ª©ng kho√°n Vi·ªát Nam. 2. Thanh to√°n ch·ª©ng kho√°n ƒë∆∞·ª£c th·ª±c hi·ªán tr√™n h·ªá th·ªëng t√†i kho·∫£n l∆∞u k√Ω t·∫°i T·ªïng c√¥ng ty l∆∞u k√Ω v√† b√π tr·ª´ ch·ª©ng kho√°n Vi·ªát Nam, thanh to√°n ti·ªÅn giao d·ªãch ch·ª©ng kho√°n ƒë∆∞·ª£c th·ª±c hi·ªán qua ng√¢n h√†ng thanh to√°n v√† ph·∫£i tu√¢n th·ªß nguy√™n t·∫Øc chuy·ªÉn giao ch·ª©ng kho√°n ƒë·ªìng th·ªùi v·ªõi thanh to√°n ti·ªÅn. 3. B·ªô tr∆∞·ªüng B·ªô T√†i ch√≠nh quy ƒë·ªãnh c√°c bi·ªán ph√°p x·ª≠ l√Ω trong tr∆∞·ªùng h·ª£p th√†nh vi√™n c·ªßa T·ªïng c√¥ng ty l∆∞u k√Ω v√† b√π tr·ª´ ch·ª©ng kho√°n Vi·ªát Nam t·∫°m th·ªùi m·∫•t kh·∫£ nƒÉng thanh to√°n giao d·ªãch ch·ª©ng kho√°n.",
            "expected": "<ORGANIZATION> T·ªïng c√¥ng ty l∆∞u k√Ω v√† b√π tr·ª´ ch·ª©ng kho√°n Vi·ªát Nam <LEGAL_PROVISION> ƒêi·ªÅu 63 <Relates_To> <ORGANIZATION> T·ªïng c√¥ng ty l∆∞u k√Ω v√† b√π tr·ª´ ch·ª©ng kho√°n Vi·ªát Nam <ORGANIZATION> ng√¢n h√†ng thanh to√°n <Relates_To> <ORGANIZATION> B·ªô T√†i ch√≠nh <ORGANIZATION> T·ªïng c√¥ng ty l∆∞u k√Ω v√† b√π tr·ª´ ch·ª©ng kho√°n Vi·ªát Nam <Relates_To>"
        }
    ]
    
    print("=" * 80)
    print("TESTING FINETUNED ViLegalJERE MODEL")
    print("=" * 80)
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nüß™ TEST CASE {i}: {test_case['id']}")
        print("-" * 60)
        
        print(f"üìù INPUT CONTEXT:")
        print(f"{test_case['context'][:200]}...")
        
        print(f"\nüéØ EXPECTED RELATIONS:")
        print(f"{test_case['expected'][:150]}...")
        
        print(f"\nü§ñ MODEL GENERATED:")
        try:
            generated_text, relations = generate_relations(model, tokenizer, device, test_case['context'])
            print(f"{generated_text}")
            
            # Simple evaluation
            if generated_text and len(generated_text) > 10:
                print(f"‚úÖ Generation successful ({len(generated_text)} chars)")
                
                # Check if output contains expected patterns
                has_entities = any(tag in generated_text for tag in ["<ORGANIZATION>", "<LOCATION>", "<RIGHT/DUTY>", "<LEGAL_PROVISION>"])
                has_relations = "<Relates_To>" in generated_text
                
                if has_entities and has_relations:
                    print(f"‚úÖ Output format looks correct (has entities and relations)")
                    print(f"üéØ Extracted {len(relations)} relations:")
                    for i, rel in enumerate(relations[:3]):  # Show first 3 relations
                        print(f"   {i+1}. {rel['head']} ({rel['head_type']}) --{rel['relation']}--> {rel['tail']} ({rel['tail_type']})")
                else:
                    print(f"‚ö†Ô∏è Output format may be incorrect")
                    print(f"üéØ Extracted {len(relations)} relations")
            else:
                print("‚ùå Generation failed or too short")
                
        except Exception as e:
            print(f"‚ùå Generation error: {e}")
        
        print("\n" + "="*60)

if __name__ == "__main__":
    test_model()
